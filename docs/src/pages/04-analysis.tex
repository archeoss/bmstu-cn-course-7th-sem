% Контекст: это Научно Исследовательская Работа. Цель работы - анализ методов распределенных вычислений в распределенных системах хранения информации.

\section{Аналитическая часть}

По варианту задания статик сервер должен обладать следующими требованиями:
\begin{enumerate}
	\item поддержка запросов \texttt{GET} и \texttt{HEAD} (поддержка статусов 200, 403, 404);
	\item ответ на Неподдерживаемые запросы статусом 405;
	\item корректное выставление content type в зависимости от типа файла (поддержка .html, .css, .js, .png, .jpg, .jpeg, .swf, .gif);
	\item корректная передача файлов размером в 100мб;
	\item сервер по умолчанию должен возвращать html-страницу на выбранную тему с css-стилем;
	\item архитектура thread pool + poll.
\end{enumerate}

Должны быть учтены минимальные требования к безопасности статик-серверов. Должен быть реализовать логгер. В качестве инструментов разработки должен быть Использован язык C без сторонних библиотек. По результатам разработки должно быть проведено нагрузочное тестирование.

\subsection{Статик сервер}

Статический сервер -- это программа или сервис, обрабатывающий запросы на получение статических файлов (например, HTML, CSS, JavaScript, изображения). Он не выполняет динамическую обработку данных и предоставляет файлы клиентам без изменений. Основная задача статического сервера -- быстрая и эффективная отдача контента, минимизация задержек и обеспечение безопасности

\subsection{Протокол HTTP}

Рассмотрение современных веб-технологий невозможно без глубокого понимания протокола HTTP (Hypertext Transfer Protocol). 
Этот стандарт представляет собой основной механизм взаимодействия между веб-клиентами и серверами, обеспечивая передачу данных в формате гипертекста. 
HTTP сыграл ключевую роль в развитии интернета и является основой для передачи ресурсов, таких как HTML-страницы, изображения, стили и другие~\cite{cn}.

Протокол HTTP оперирует по принципу запрос-ответ, где клиент посылает запрос на сервер для получения определенного ресурса, и сервер возвращает соответствующий ответ. 
Этот обмен сообщениями строится вокруг простых принципов и стандартов, что позволяет веб-клиентам и серверам эффективно
обмениваться информацией.

Существует несколько версий протокола HTTP, каждая из которых вносит улучшения и нововведения. 
В контексте данной работы выбран HTTP 1.1, поскольку он предоставляет возможность многократного использования соединений (connection reuse). 
Эта характеристика позволяет снизить задержки при обмене данными, поскольку после завершения одного запроса соединение может быть переиспользовано для последующих запросов, сэкономив трафик и улучшив производительность. 
В работе более детально рассмотрены механизмы переиспользования соединений в рамках HTTP 1.1 и их влияние на эффективность веб-взаимодействия.

В рамках рассмотрения альтернативных версий протокола HTTP, особое внимание привлекает HTTP/2.0. 
Эта версия была представлена с целью оптимизации производительности и улучшения пользовательского опыта в сравнении с ее предшественником, HTTP/1.1. 
Основными изменениями, внесенными в HTTP/2.0, стали многопоточность, мультиплексирование и сжатие заголовков, что привело к уменьшению задержек и более эффективному использованию ресурсов.

Мультиплексирование позволяет одновременно передавать несколько запросов и ответов в рамках одного соединения. 
Это снижает задержки и улучшает пропускную способность, что особенно важно в условиях медленных сетей или при использовании мобильных устройств. 
Сжатие заголовков также содействует более эффективной передаче данных~\cite{tan}. 
Тем не менее, несмотря на ряд явных преимуществ, выбор HTTP/2.0 для данного проекта не был сделан. 
HTTP/2.0, несмотря на свою эффективность, обладает более сложной структурой и требует более глубокого понимания принципов мультиплексирования и других инноваций, что может создать дополнительные сложности в учебных целях.

Таким образом, выбор HTTP 1.1 для данного проекта обоснован стремлением к более непосредственному и понятному представлению студентам основ работы веб-сервера и протокола HTTP.

\subsection{Архитектура}

Традиционно существует две конкурирующие серверные архитектуры: одна основана на потоках, другая -- на событиях. Со временем появились более сложные варианты, иногда сочетающие оба подхода. В течение долгого времени велся спор о том, являются ли потоки или события лучшей основой для высокопроизводительных веб-серверов \cite{monadic}. Спустя более чем десятилетие этот аргумент усилился благодаря новым проблемам масштабируемости и тенденции к использованию многоядерных процессоров.

\subsubsection{Поточная архитектура}

Потоковый подход в основном связывает каждое входящее соединение с отдельным потоком (соответственно процессом). Таким образом, синхронная блокировка ввода-вывода является естественным способом обработки ввода-вывода. Это распространённый подход, который хорошо поддерживается многими языками программирования. Это также приводит к созданию простой модели программирования, поскольку все задачи, необходимые для обработки запросов, могут быть запрограммированы последовательно. Более того, он обеспечивает простую мысленную абстракцию, изолируя запросы и скрывая параллелизм. Реальный параллелизм достигается за счёт одновременного использования нескольких потоков/процессов.

Концептуально многопроцессные и многопоточные архитектуры разделяют одни и те же принципы: каждое новое соединение обрабатывается специальным действием.

\subsubsection{Процессная архитектура}

Традиционным подходом к сетевым серверам на базе UNIX является модель <<процесс для каждого соединения>> \cite{unix-prog}, в которой используется выделенный процесс для обработки соединения. Эта модель также использовалась для первого HTTP-сервера CERN httpd \cite{w3daemon}. Из-за особенностей процессов они быстро изолируют разные запросы, поскольку они не используют общую память. Поскольку создание процессов является довольно тяжеловесной структурой, оно является дорогостоящей операцией, и серверы часто используют стратегию, называемую предварительным разветвлением. При использовании предварительного разветвления основной серверный процесс упреждающе разветвляет несколько процессов-обработчиков при запуске. Часто дескриптор сокета (потокобезопасный) используется всеми процессами, и каждый процесс блокирует новое соединение, обрабатывает его, а затем ожидает следующего соединения.

Некоторые многопроцессные серверы также измеряют нагрузку и при необходимости создают дополнительные запросы. Однако важно отметить, что тяжёлая структура процесса ограничивает максимальное количество одновременных подключений. Большой объём памяти, используемый в результате сопоставления процесса соединения, приводит к компромиссу между параллелизмом и памятью. Многопроцессная архитектура обеспечивает лишь ограниченную масштабируемость для одновременных запросов, особенно в случае длительных, частично неактивных соединений (например, запросов на уведомления с длительным опросом).

Популярный веб-сервер Apache предоставляет надёжный многопроцессорный модуль, основанный на предварительном разветвлении процессов, предварительном разветвлении Apache-MPM. Это по-прежнему многопроцессорный модуль по умолчанию для UNIX-установок Apache.
Многопоточные архитектуры

\subsubsection{Многопоточная архитектура}

Когда стали доступны библиотеки потоков, появились новые серверные архитектуры, которые заменили тяжёлые процессы более лёгкими потоками. По сути, они используют модель <<поток на соединение>>. Хотя многопоточный подход основан на тех же принципах, он имеет несколько важных отличий. Прежде всего, несколько потоков используют одно и то же адресное пространство и, следовательно, используют общие глобальные переменные и состояние. Это позволяет реализовать общие функции для всех обработчиков запросов, такие как общий кеш для кэшируемых ответов внутри веб-сервера. Очевидно, что тогда потребуется правильная синхронизация и координация. Ещё одним отличием более лёгких структур потоков является меньший объем памяти. По сравнению с полноценным объёмом памяти всего процесса, поток потребляет лишь ограниченную память (т. е. стек потоков). Кроме того, потоки требуют меньше ресурсов для создания/завершения. Мы уже видели, что размеры процесса представляют собой серьёзную проблему в случае высокого уровня параллелизма. Потоки, как правило, являются более эффективной заменой при сопоставлении соединений с действиями.

На практике общепринятой архитектурой является размещение одного потока-диспетчера (иногда называемого потоком-получателем) перед пулом потоков для обработки соединений, как показано на рисунке. Пулы потоков -- это распространённый способ ограничения максимального количества потоков внутри сервера. Диспетчер блокирует сокет для новых соединений. После установки соединение передаётся в очередь входящих соединений. Потоки из пула потоков принимают соединения из очереди, выполняют запросы и ждут новых соединений в очереди. Если очередь также ограничена, максимальное количество ожидающих соединений может быть ограничено. Дополнительные подключения будут отклонены. Хотя эта стратегия ограничивает параллелизм, она обеспечивает более предсказуемые задержки и предотвращает полную перегрузку.

Apache-MPM -- это многопроцессорный модуль для веб-сервера Apache, который объединяет процессы и потоки. Модуль порождает несколько процессов, и каждый процесс, в свою очередь, управляет собственным пулом потоков.

Многопоточные серверы, использующие модель <<поток на соединение>>, легко реализовать и следуют простой стратегии. Синхронные блокирующие операции ввода-вывода могут использоваться как естественный способ выражения доступа к вводу-выводу. Операционная система перекрывает несколько потоков посредством упреждающего планирования. В большинстве случаев, по крайней мере, блокирующая операция ввода-вывода запускает планирование и вызывает переключение контекста, позволяя продолжить работу следующему потоку. Это надёжная модель для достойного параллелизма, а также подходящая, когда необходимо выполнить разумное количество операций, связанных с ЦП. Кроме того, можно использовать несколько ядер ЦП напрямую, поскольку потоки и процессы планируются для всех доступных ядер.

При большой нагрузке многопоточный веб-сервер потребляет большие объёмы памяти (из-за одного стека потоков для каждого соединения), а постоянное переключение контекста приводит к значительным потерям процессорного времени. Косвенным наказанием за это является повышенная вероятность промахов в кэше ЦП. Уменьшение абсолютного количества потоков повышает производительность каждого потока, но ограничивает общую масштабируемость с точки зрения максимального количества одновременных подключений.

\subsection{Событийная архитектура}

В качестве альтернативы синхронному блокированию ввода-вывода в серверных архитектурах также распространён подход, управляемый событиями. Из-за семантики асинхронных/неблокирующих вызовов необходимы другие модели, кроме ранее описанной модели <<поток на соединение>>. Распространённой моделью является сопоставление одного потока с несколькими соединениями. Затем поток обрабатывает все события, происходящие в результате операций ввода-вывода этих соединений и запросов. Новые события ставятся в очередь, и поток выполняет так называемый цикл обработки событий: удаляет события из очереди, обрабатывает событие, затем принимает следующее событие или ожидает отправки новых событий. Таким образом, работа, выполняемая потоком, очень похожа на работу планировщика, объединяющего несколько соединений в один поток выполнения.

Обработка события либо требует зарегистрированного кода обработчика событий для конкретных событий, либо основана на выполнении обратного вызова, заранее связанного с событием. Различные состояния соединений, обрабатываемых потоком, организованы в соответствующие структуры данных — либо явно с использованием конечных автоматов, либо неявно через продолжения или закрытия обратных вызовов. В результате поток управления приложением, использующим событийно-ориентированный стиль, каким-то образом инвертируется. Вместо последовательных операций программа, управляемая событиями, использует каскад асинхронных вызовов и обратных вызовов, которые выполняются при возникновении событий. Это понятие часто делает поток управления менее очевидным и усложняет отладку.

Использование серверных архитектур, управляемых событиями, исторически зависело от наличия асинхронных/неблокирующих операций \\* ввода-вывода на уровне ОС и подходящих высокопроизводительных интерфейсов уведомления о событиях, таких как epoll и kqueue. Более ранние реализации серверов, основанных на событиях, таких как веб-сервер Flash \cite{vivek}.

Наличие одного потока, выполняющего цикл событий и ожидающего уведомлений о вводе-выводе, оказывает иное влияние на масштабируемость, чем подход на основе потоков, описанный ранее. Отсутствие связывания соединений и потоков существенно уменьшает количество потоков сервера — в крайнем случае, вплоть до одного потока цикла событий плюс некоторых потоков ядра ОС для ввода-вывода. Тем самым мы избавляемся от накладных расходов на чрезмерное переключение контекста и не нуждаемся в стеке потоков для каждого соединения. Это уменьшает объем памяти под нагрузкой и тратит меньше времени процессора на переключение контекста. В идеале ЦП становится единственным очевидным узким местом сетевого приложения, управляемого событиями. Пока не будет заархивировано полное насыщение ресурсов, цикл событий масштабируется с увеличением пропускной способности. Как только нагрузка превышает максимальное насыщение, очередь событий начинает накапливаться, поскольку поток обработки событий не может соответствовать. В этом случае подход, управляемый событиями, по-прежнему обеспечивает высокую пропускную способность, но задержки запросов увеличиваются линейно из-за перегрузки. Это может быть приемлемо для временных пиков нагрузки, но постоянная перегрузка снижает производительность и делает службу непригодной для использования. Одной из контрмер является более ресурсосберегающее планирование и разделение обработки событий, как мы вскоре увидим при анализе поэтапного подхода.

На данный момент придерживаются событийно-ориентированных архитектур и согласовываем их с многоядерными архитектурами. Хотя модель на основе потоков охватывает как параллелизм на основе ввода-вывода, так и на основе ЦП, первоначальная архитектура, основанная на событиях, касается исключительно параллелизма ввода-вывода. Для использования нескольких процессоров или ядер серверы, управляемые событиями, должны быть дополнительно адаптированы.

Очевидный подход -- создание нескольких отдельных серверных процессов на одной машине. Это часто называют подходом N-копирования для использования N экземпляров на хосте с N процессорами/ядрами. В нашем случае на машине будет запускаться несколько экземпляров веб-сервера и регистрироваться все экземпляры на балансировщиках нагрузки. Менее изолированная альтернатива использует общий сокет сервера между всеми экземплярами, что требует некоторой координации. Например, реализация этого подхода доступна для node.js с использованием модуля кластера, который разветвляет несколько экземпляров приложения и использует один серверный сокет.

Веб-серверы в архитектурной модели имеют специфическую особенность -- они не имеют состояния и не имеют общего доступа. Уже использование внутреннего кэша для динамических запросов требует внесения некоторых изменений в архитектуру сервера. На данный момент более простая модель параллелизма, состоящая из однопоточного сервера и семантики последовательного выполнения обратных вызовов, может быть принята как часть архитектуры. Именно эта простая модель выполнения делает однопоточные приложения привлекательными для разработчиков, поскольку усилия по координации и синхронизации уменьшаются, а код приложения (то есть обратные вызовы) гарантированно не будет выполняться одновременно.

\subsection{Смешанный подход}

Потребность в масштабируемых архитектурах и недостатки обеих общих моделей привели к появлению альтернативных архитектур и библиотек, включающих в себя функции обеих моделей.

\subsubsection{Поэтапная событийно-ориентированная архитектура}

Формирующая архитектура, объединяющая потоки и события для масштабируемых серверов, была разработана Уэлшем, так называемый SEDA \cite{seda}. В качестве базовой концепции логика сервера разделена на ряд чётко определённых этапов, соединённых очередями. В процессе обработки запросы передаются от этапа к этапу. Каждый этап поддерживается потоком или пулом потоков, который можно настроить динамически.

Такое разделение благоприятствует модульности, поскольку конвейер этапов можно легко изменить и расширить. Ещё одной очень важной особенностью конструкции SEDA является осведомлённость о ресурсах и явный контроль нагрузки. Размер элементов в очереди на этап и рабочая нагрузка пула потоков на этап дают чёткое представление об общем коэффициенте загрузки. В случае перегрузки сервер может настроить параметры планирования или размеры пула потоков. Другие адаптивные стратегии включают динамическую реконфигурацию конвейера или намеренное завершение запроса. Когда управление ресурсами, самоанализ нагрузки и адаптивность отделены от логики приложения этапа, разрабатывать хорошо обусловленные сервисы становится проще. С точки зрения параллелизма SEDA представляет собой гибридный подход между многопоточностью «поток на соединение» и параллелизмом на основе событий. Наличие элементов удаления из очереди и обработки потока (или пула потоков) напоминает подход, управляемый событиями. Использование нескольких этапов с независимыми потоками эффективно задействует несколько процессоров или ядер и способствует созданию многопоточной среды. С точки зрения разработчика, реализация кода-обработчика для определённого этапа также напоминает более традиционное программирование потоков.

Недостатками SEDA являются повышенные задержки из-за обхода очередей и стадий даже при минимальной нагрузке. В более поздней ретроспективе Уэлш также раскритиковал отсутствие дифференциации границ модулей (этапов) и границ параллелизма (очередей и потоков). Такое распределение вызывает слишком много переключений контекста, когда запросы проходят через несколько этапов и очередей. Лучшее решение группирует несколько этапов вместе с общим пулом потоков. Это уменьшает переключение контекста и улучшает время отклика. Этапы с операциями ввода-вывода и сравнительно длительным временем выполнения все же можно изолировать.

Модель SEDA вдохновила на создание нескольких реализаций, включая базовую серверную структуру Apache MINA \cite{mina} и корпоративные сервисные шины, такие как Mule ESB \cite{mulesoft}.

\subsubsection{Специальные библиотеки}

Другие подходы были сосредоточены на недостатках потоков в целом и проблемах доступных библиотек потоков (на пользовательском уровне) в частности. Как мы скоро увидим, большинство проблем масштабируемости потоков связаны с недостатками их библиотек.

Например, библиотека потоков Capriccio, созданная фон Береном обещает масштабируемые потоки для серверов, решая основные проблемы потоков. Проблема обширных переключений контекста решается с помощью невытесняющего планирования. Потоки либо выдают результат при операциях ввода-вывода, либо при явной операции вывода. Размер стека каждого потока ограничен на основе предварительного анализа во время компиляции. Это делает ненужным упреждающее избыточное предоставление ограниченного пространства стека. Однако неограниченные циклы и использование рекурсивных вызовов делают полный расчёт размера стека априори невозможным. В качестве обходного пути в код вставляются контрольные точки, которые определяют, произойдёт ли переполнение стека, и в этом случае выделяют новые фрагменты стека. Контрольные точки вставляются во время компиляции и размещаются таким образом, чтобы в коде никогда не возникало переполнение стека между двумя контрольными точками. Кроме того, применяется планирование с учётом ресурсов, которое предотвращает перегрузку. Таким образом, дескрипторы ЦП, памяти и файлов отслеживаются и сочетаются со статическим анализом использования ресурсов потоков, планирование динамически адаптируется.

Также разработаны гибридные библиотеки, объединяющие потоки и события. Ли и Зданцевик реализовали комбинированную модель для Haskell \cite{haskell-lib}, основанную на монадах параллелизма. Язык программирования Scala также обеспечивает управляемый событиями и многопоточный параллелизм, который можно комбинировать для серверных реализаций.

\subsection*{Выводы}

Проблема масштабируемости веб-серверов характеризуется интенсивным параллелизмом HTTP-соединений. Таким образом, основной проблемой является массовый параллелизм операций ввода-вывода. Когда несколько клиентов одновременно подключаются к серверу, ресурсы сервера, такие как время процессора, память и ёмкость сокетов, должны строго планироваться и использоваться, чтобы одновременно поддерживать низкие задержки ответа и высокую пропускную способность. Поэтому мы рассмотрели различные модели операций ввода-вывода и способы представления запросов в модели программирования, поддерживающей параллелизм. Мы сосредоточились на различных серверных архитектурах, которые обеспечивают различные комбинации вышеупомянутых концепций, а именно: многопроцессные серверы, многопоточные серверы, серверы, управляемые событиями, и комбинированные подходы, такие как SEDA.

Разработка высокопроизводительных серверов, использующих потоки, события или и то, и другое, стала реальной возможностью. Однако традиционная синхронная модель блокирующего ввода-вывода страдает от снижения производительности, когда она используется как часть массового параллелизма ввода-вывода. Аналогичным образом, использование большого количества потоков ограничивается увеличением потерь производительности в результате постоянного переключения контекста и потребления памяти из-за размеров стека потоков. С другой стороны, серверные архитектуры, управляемые событиями, страдают от менее понятного стиля программирования и часто не могут напрямую воспользоваться преимуществами истинного параллелизма ЦП. Комбинированные подходы пытаются специально обойти проблемы, присущие одной из моделей, или предлагают концепции, включающие обе модели.

Теперь мы увидели, что подходы, основанные на потоках и событиях, по сути являются двойниками друг друга и уже долгое время разделяют сообщество сетевых серверов. Получение преимуществ совместного планирования и асинхронных/неблокирующих операций ввода-вывода является одним из основных желаний серверных приложений, ориентированных на ввод-вывод, однако это часто упускается из виду в более широком и смешанном споре между лагерем потоков и лагерем событий.

\clearpage
